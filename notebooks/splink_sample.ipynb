{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f33e6865-2129-48d2-9f2e-3f237792007d",
   "metadata": {},
   "source": [
    "### Splink Notes\n",
    "\n",
    "[(sp)link to the docs](https://moj-analytical-services.github.io/splink/)\n",
    "\n",
    "Cleaning Requirements\n",
    "- columns shouldn't be correlated\n",
    "  - profile data with `profile_columns`\n",
    "- strings are cleaned\n",
    "- matching columns have same name in both datasets\n",
    "\n",
    "Pros\n",
    "- good charts, eg. you can see a match weights waterfall charts to see how column comparison contributes to the match score, cluster charts, comparison vectors etc.\n",
    "- you can see the comparison levels of match probability - shows the match weight of exact matches versus match weights of levenstein distance <= 2, versus all other comparisons, numeric columns might have just 2 match levels (exact match versus not match)\n",
    "- good charts makes the model much more intuitive, plant name should likely have a higher match weight than fuel type\n",
    "- built in data profile\n",
    "- very responsive on GitHub and and good upkeep of the tool\n",
    "\n",
    "Cons\n",
    "- columns needed to be compared directly because the names need to match? Idea: maybe you could try to rename columns that have a lookup dictionary - fuel_type_code_pudl_energy_source_code to relate FTCP and energy source code\n",
    "- can't have dependencies in columns - seems like it doesn't do as well with dependencies in records\n",
    "- how does it handle transitivity in the records? if FERC_A links to EIA_B then FERC_A also links to EIA_A\n",
    "- how will it handle data on the EIA side that isn't going to be linked to a FERC record?\n",
    "- not the best documentation - had to pick through the source code\n",
    "- the error messages aren't very helpful or there is a lack of error messaging\n",
    "\n",
    "Questions:\n",
    "- Would this work best for connecting the FERC plants and assigning `plant_id_pudl`? Could do a dedupe maybe?\n",
    "   \n",
    "\n",
    "Steps:\n",
    "- profile data\n",
    "- clean values and columns\n",
    "- train u values - `train_u_using_random_sampling`\n",
    "    - u value: what is the probability of collisions even when records don't match? you can get good estimates of the u values just with comparing random samples\n",
    "- train m values - `train_m_using_expectation_maximisation`, one EM iteration for all blocking rules (just report year?)\n",
    "    - m value: reports the data quality: amongst matches how often do we get collisions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e701c0b6-6c82-4f75-bc9c-876d1000951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from splink.duckdb.duckdb_linker import DuckDBLinker\n",
    "import splink.duckdb.duckdb_comparison_library as cl\n",
    "import splink.duckdb.duckdb_comparison_level_library as cll\n",
    "import sqlalchemy as sa\n",
    "\n",
    "import pudl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3d2761-2454-4d26-a9cc-84439bae2be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pudl_engine = sa.create_engine(pudl.workspace.setup.get_defaults()['pudl_db'])\n",
    "pudl_out = pudl.output.pudltabl.PudlTabl(pudl_engine, freq=\"AS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f04f39-dd2b-4827-b4bc-a452407a7a5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load the Data\n",
    "Start with the input data to Panda. \n",
    "- EIA distinct plant parts data filtered to just gens for 2020\n",
    "- Full FERC \n",
    "\n",
    "Then try without breaking apart by plant part.\n",
    "\n",
    "- do the missingness analysis early, get rid of columns with lots of nulls\n",
    "- rename columns that don't match (fuel type)\n",
    "- filter for just 2020 and generators\n",
    "- get rid of dependent columns\n",
    "- do the link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4226c3e-be93-4313-9f8c-77022c185e7a",
   "metadata": {},
   "source": [
    "Read in pickled version of plant parts list or generate a fresh one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b033994-9780-4fed-a238-e0f6d88dedc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have it, read in pickled dataframe\n",
    "eia_df = pd.read_pickle(\"plant_parts_eia_distinct.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd55a61-6d1f-42ed-9a7c-b6c292956d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make ppl distinct for Panda\n",
    "# this was adapted from the RMI repo\n",
    "# takes as input a non-distinct (includes non true grans) ppl\n",
    "def get_plant_parts_distinct(plant_parts_eia):\n",
    "    \"\"\"Get the EIA plant-parts with only the unique granularities.\"\"\"\n",
    "    # We want only the records of the EIA plant-parts that are \"true\n",
    "    # granularies\" and those which are not duplicates based on their\n",
    "    # ownership  so the model doesn't get confused as to which option to\n",
    "    # pick if there are many records with duplicate data\n",
    "    plant_parts_eia = plant_parts_eia.assign(\n",
    "        plant_id_report_year_util_id=lambda x: x.plant_id_report_year\n",
    "        + \"_\"\n",
    "        + x.utility_id_pudl.map(str)\n",
    "    ).astype({\"installation_year\": \"float\"})\n",
    "    plant_parts_distinct = plant_parts_eia[\n",
    "        (plant_parts_eia[\"true_gran\"]) & (~plant_parts_eia[\"ownership_dupe\"])\n",
    "    ]\n",
    "    return plant_parts_distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22fea9f-30f2-4197-9a20-907babc65d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# else, generate a new PPE and make it distinct\n",
    "plant_parts_eia = pudl_out.plant_parts_eia()\n",
    "# a little patch, this might not be needed anymore\n",
    "plant_parts_eia = plant_parts_eia[~plant_parts_eia.index.duplicated(keep=\"first\")]\n",
    "eia_df = get_plant_parts_distinct(plant_parts_eia)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294dd70c-f6c4-4896-b5fa-553475ff279f",
   "metadata": {},
   "source": [
    "Pick up here after generating the PPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db93bbbb-ad36-4366-ba5e-5f9cd1bf98ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently df is intended to be the distinct plant parts list\n",
    "def add_utility_name(df, pudl_engine):\n",
    "    # join on utility_name_eia\n",
    "    eia_util = pd.read_sql(\"utilities_eia\", pudl_engine)\n",
    "    eia_util = eia_util.set_index('utility_id_eia')['utility_name_eia']\n",
    "    non_null_df = df[~(df.utility_id_eia.isnull())]\n",
    "    non_null_df = non_null_df.merge(eia_util, how=\"left\", left_on='utility_id_eia', right_index=True, validate=\"m:1\")\n",
    "    df_util = pd.concat([non_null_df, df[df.utility_id_eia.isnull()]])\n",
    "    df = df_util.reindex(df.index)\n",
    "    \n",
    "    return df_util"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3c8579-cedc-4c86-a202-8f869b8bc4bf",
   "metadata": {},
   "source": [
    "Instead of filtering for 2020 data, maybe it would work better if this was built in as a blocking rule. Ideally it would be good to have no other blocking rules besides report_year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9d48fc-9be0-47de-be2e-245305703cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_df = eia_df[eia_df.report_year == 2020]\n",
    "eia_df = eia_df[eia_df.plant_part == \"plant_gen\"]\n",
    "eia_df = add_utility_name(eia_df, pudl_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569447b-0608-4cdc-b153-e15622b04de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not useful for matching, drop now to clean up missingness chart\n",
    "extra_cols = [\"appro_part_label\",\n",
    "              \"appro_record_id_eia\",\n",
    "              \"fraction_owned\",\n",
    "              \"ownership\",\n",
    "              \"ownership_dupe\",\n",
    "              \"plant_part\",\n",
    "              \"plant_id_report_year\",\n",
    "              \"plant_id_report_year_util_id\",\n",
    "              \"plant_part_id_eia\",\n",
    "              \"record_count\",\n",
    "              \"true_gran\"]\n",
    "eia_df = eia_df.drop(columns=extra_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e7a624-2a78-4782-85d9-c850b2ab0522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the cleaned ferc table if you have it\n",
    "ferc_df = pd.read_pickle(\"full_ferc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19ab2a-cc28-4c8b-bf7e-31115db581d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or generate a fresh one (this is from RMI repo)\n",
    "def get_ferc_plants(pudl_out):\n",
    "    fbp_cols_to_use = [\n",
    "        \"report_year\",\n",
    "        \"utility_id_ferc1\",\n",
    "        \"plant_name_ferc1\",\n",
    "        \"utility_id_pudl\",\n",
    "        \"fuel_cost\",\n",
    "        \"fuel_mmbtu\",\n",
    "        \"primary_fuel_by_mmbtu\",\n",
    "    ]\n",
    "    plants_ferc1_df = (\n",
    "        pudl_out.plants_all_ferc1()\n",
    "        .merge(\n",
    "            pudl_out.fbp_ferc1()[fbp_cols_to_use],\n",
    "            on=[\n",
    "                \"report_year\",\n",
    "                \"utility_id_ferc1\",\n",
    "                \"utility_id_pudl\",\n",
    "                \"plant_name_ferc1\",\n",
    "            ],\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .pipe(pudl.helpers.convert_cols_dtypes, \"ferc1\")\n",
    "        .assign(\n",
    "            installation_year=lambda x: (\n",
    "                x.installation_year.astype(\"float\")\n",
    "            ),  # need for comparison vectors\n",
    "            plant_id_report_year=lambda x: (\n",
    "                x.plant_id_pudl.map(str) + \"_\" + x.report_year.map(str)\n",
    "            ),\n",
    "            plant_id_report_year_util_id=lambda x: (\n",
    "                x.plant_id_report_year + \"_\" + x.utility_id_pudl.map(str)\n",
    "            ),\n",
    "            fuel_cost_per_mmbtu=lambda x: (x.fuel_cost / x.fuel_mmbtu),\n",
    "            heat_rate_mmbtu_mwh=lambda x: (x.fuel_mmbtu / x.net_generation_mwh),\n",
    "        )\n",
    "        .rename(\n",
    "            columns={\n",
    "                \"record_id\": \"record_id_ferc1\",\n",
    "                \"opex_plants\": \"opex_plant\",\n",
    "                \"fuel_cost\": \"total_fuel_cost\",\n",
    "                \"fuel_mmbtu\": \"total_mmbtu\",\n",
    "                \"opex_fuel_per_mwh\": \"fuel_cost_per_mwh\",\n",
    "                \"primary_fuel_by_mmbtu\": \"fuel_type_code_pudl\",\n",
    "            }\n",
    "        )\n",
    "        .set_index(\"record_id_ferc1\")\n",
    "    )\n",
    "    return plants_ferc1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ca555c-a614-41bc-a7f0-26e2764d650c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ferc_df = get_ferc_plants(pudl_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b33b3-abf0-4a93-bcb5-30bce7da9793",
   "metadata": {},
   "outputs": [],
   "source": [
    "ferc_df = ferc_df[ferc_df.report_year == 2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86f31a8-a069-4a69-931d-aa0b3c26b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker_eia = DuckDBLinker(eia_df)\n",
    "linker_ferc = DuckDBLinker(ferc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5598ec-d584-434f-827a-d0d2c6b23ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker_eia.missingness_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa36cc7-3709-44a2-9a42-7d5fd628e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop cols that are more than 80% null\n",
    "percent_null = eia_df.isnull().sum() / len(eia_df)\n",
    "cols_to_drop = list(set(percent_null[percent_null >= .8].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b35551-44ec-4a23-ac41-7a04717fcea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_df = eia_df.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c77d71d-53a8-4f3c-90a6-db3b6a166bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker_ferc.missingness_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a160ec92-46e4-4797-8f24-eae6dcc3cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_df = eia_df.rename(columns={\"plant_name_eia\": \"plant_name\", \"utility_name_eia\": \"utility_name\"})\n",
    "ferc_df = ferc_df.rename(columns={\"plant_name_ferc1\": \"plant_name\", \"utility_name_ferc1\": \"utility_name\"})\n",
    "shared_cols = list(set(eia_df.columns) & set(ferc_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbc34a2-61ad-4897-9c11-0fe90aed6c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428bc08a-2f88-4f20-8f82-3a51f1711eb9",
   "metadata": {},
   "source": [
    "TODO: look at `compare_multiple_columns_to_single_column_level`. I think this would allow us to compare columns that don't match (only for exact match but could make own function that does a string distance). I think the non-exact match could be done by specifying a distance function for a level with `DistanceFunctionLevelBase` (or one of the specific functions). Added in [this PR](https://github.com/moj-analytical-services/splink/pull/720)\n",
    "\n",
    "Since we are only using columns that match, we can naively have `plant_type` on the FERC side map to `technology_description` on the EIA side. This is really not a very good mapping, but for now let's not mess with the columns too much, in a future iteration we could concatenate string columns together into one column or make a dictionary mapping plant type to technology description.\n",
    "\n",
    "Note: this naive mapping might be making results worse in this baseline model, but I wanted a column representing the plant type to make it in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0849c03-d98e-4ca7-a20f-ddaa1b2d791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ferc_df.plant_type.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90ddc37-9999-4359-b125-0c0a7adeff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "ferc_df = ferc_df.rename(columns={\"plant_type\": \"technology_description\"})\n",
    "shared_cols = list(set(eia_df.columns) & set(ferc_df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6eec718-fe05-4657-b89d-d0cda6c940b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splink doesn't do well when columns are dependent\n",
    "# some of these columns seem somewhat dependent (technology_description and capacity_mw) but let's just try\n",
    "shared_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f576bf91-5184-41a1-8f28-f228fb61614c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's not actually necessary for all columns to match for splink to work\n",
    "# it's just cleaner to look at the dataframes\n",
    "ferc_df = ferc_df[shared_cols]\n",
    "eia_df = eia_df[shared_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534dfee-3e42-4af2-82ca-227e69ce3ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4863c511-0f0c-4ef1-b51c-39d1ffc8c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_df = eia_df.astype({\n",
    "    \"technology_description\": \"string\", \n",
    "    \"installation_year\": \"Int64\", \n",
    "    \"construction_year\": \"Int64\",\n",
    "    \"capacity_mw\": \"float64\",\n",
    "    \"utility_name\": \"string\",\n",
    "    \"plant_name\": \"string\",\n",
    "    \"fuel_type_code_pudl\": \"string\"})\n",
    "eia_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf68129c-010d-484f-807d-d95485c50a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ferc_df = ferc_df.astype(eia_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1148a164-a7ff-4b61-8eec-ef899c4d6854",
   "metadata": {},
   "outputs": [],
   "source": [
    "ferc_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f4a7b5-6e1c-4294-ae19-f4c11220e087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic column string clean up, could do something more thorough later\n",
    "# technology description really doesn't map very well between FERC and EIA right now\n",
    "str_cols = [\"utility_name\", \"plant_name\", \"technology_description\"]\n",
    "eia_df[str_cols] = eia_df[str_cols].apply(lambda x: x.str.strip().str.lower().str.replace(\" \", \"_\"))\n",
    "ferc_df[str_cols] = ferc_df[str_cols].apply(lambda x: x.str.strip().str.lower().str.replace(\" \", \"_\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc7b0c4-b151-45f4-b591-e95316887614",
   "metadata": {},
   "source": [
    "Since 0 is the most common `capacity_mw` value on the FERC side, replace 0 and negative `capacity_mw` values on the FERC side with nans. On the EIA side, `capacity_mw` values are filled/aggregated from other plant parts within the plant. There are still a few 0 values on the EIA side but not as many as FERC. Even if a 0 capacity value on the FERC side means the record represents a plant part without capacity, then it's better for this to be represented with a null value.\n",
    "\n",
    "Not completely sure if this is the right thing to do. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5eb535-1d06-4163-bc6b-5571ffde9a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eia_df[eia_df.capacity_mw == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d47f0f-64a4-4b6c-9c97-acc9b5415382",
   "metadata": {},
   "outputs": [],
   "source": [
    "ferc_df.loc[ferc_df.capacity_mw <= 0, \"capacity_mw\"] = None\n",
    "ferc_df = ferc_df.round({\"capacity_mw\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d357a7e6-53a3-4958-95db-0537d3b782c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eia_df.loc[eia_df.capacity_mw < 0, \"capacity_mw\"] = None\n",
    "eia_df = eia_df.round({\"capacity_mw\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb45d60-a8a5-4d18-9055-22e9785d306a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to make the record id index a column for splink to have a unique id col\n",
    "eia_df[\"record_id\"] = eia_df.index\n",
    "ferc_df[\"record_id\"] = ferc_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86de078-f0b2-4371-bdc3-62c0aa532c59",
   "metadata": {},
   "source": [
    "Arguments like `additional_columns_to_retain` and `retain_matching_columns` slow down matching but are nice to have when looking at end results. Maybe drop these arguments and join the columns back on if training is too slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4ee6b2-607e-4a40-b2f1-f58b15c9158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_dict = {\"link_type\": \"link_only\",\n",
    "                 \"unique_id_column_name\": \"record_id\",\n",
    "                 \"additional_columns_to_retain\": [\"plant_id_pudl\", \"utility_id_pudl\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98b2161-e732-4628-b273-d95051632413",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker = DuckDBLinker([ferc_df, eia_df], settings_dict=settings_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69564dab-225a-4431-8677-cc3b858b9261",
   "metadata": {},
   "source": [
    "### Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb8e7e9-d2b8-40f3-986b-6dab59bf36cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from altair.vegalite.v4.display import VegaLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3012fd45-8847-4d6c-a647-d08267240085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from the splink charts.py module. This is janky.\n",
    "class VegaliteNoValidate(VegaLite):\n",
    "        def _validate(self):\n",
    "            pass\n",
    "\n",
    "def display_chart(spec):\n",
    "\n",
    "        return VegaliteNoValidate(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a80aee-74ab-4720-b57d-944ef9cc19b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_chart(linker.missingness_chart(input_dataset=\"ferc_df\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462f447e-53fe-4119-975d-bbac7f532f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_chart(linker.missingness_chart(input_dataset=\"eia_df\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1830320-dbc0-4c11-9ddf-a3dd62b3c360",
   "metadata": {},
   "source": [
    "It doesn't work to do `profile_columns` with the linker that has both dataframes (I think some sort of SQL type conversion error). So for now I separated out the dataframes into two different linkers.\n",
    "\n",
    "These charts show skew in the fields we're matching on. We might want to use term frequency adjustments in our model to weight more likely matches (like PG&E) less heavily than less likely matches. I think the term frequency adjustments just normalize the match weight by the frequency of the term in the column.\n",
    "\n",
    "Columns to use `term_frequency_adjustments`: `utility_name`, `technology_description`, `fuel_type_code_pudl` (experiment with this parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb80cc4-3fda-4d58-b7c3-1368787a6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker_ferc = DuckDBLinker(ferc_df)\n",
    "linker_eia = DuckDBLinker(eia_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6438944c-adfd-418d-8b64-7e2639b8220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker_ferc.profile_columns([\n",
    "    \"plant_name\", \n",
    "    \"utility_name\", \n",
    "    \"technology_description\", \n",
    "    \"installation_year\", \n",
    "    \"construction_year\", \n",
    "    \"capacity_mw\", \n",
    "    \"fuel_type_code_pudl\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01c9357-609f-4ff8-9c68-a75bb8fe0f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker_eia.profile_columns([\n",
    "    \"plant_name\", \n",
    "    \"utility_name\", \n",
    "    \"technology_description\", \n",
    "    \"installation_year\", \n",
    "    \"construction_year\", \n",
    "    \"capacity_mw\", \n",
    "    \"fuel_type_code_pudl\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8bdeaa-8b28-48ea-9ad8-a81c552ced1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since we don't have any blocking rules, the number of possible matches is the lengths multiplied\n",
    "len(eia_df) * len(ferc_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c4ce45-f852-4b75-a0b7-5f2441809e5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define Comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdb2661-edea-4c77-9367-e8f12a76ef31",
   "metadata": {},
   "source": [
    "Is there a good way to tune these thresholds for the similarity metrics with splink?\n",
    "\n",
    "Panda was using Jaccard distance, which measures the overlap between sets of characters (and hopefully it wasn't using words). It's probably more applicable to use Levenshtein distance to get a measure of how much editing needs to be done between the strings.\n",
    "\n",
    "I hope this is using characters not words but I should double check.\n",
    "\n",
    "It seems like most of the built in comparisons are meant for strings.\n",
    "\n",
    "Experiment with adding and removing `term_frequency_adjustment`. Maybe add for `utility_name` because of the skew on the FERC side?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0d72af-8663-4d2e-b8f4-5d073da9c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try and add more thresholds too\n",
    "print(cl.levenshtein_at_thresholds(\"plant_name\", [5]).human_readable_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ac208-0dc7-4435-9f95-29833fdf16eb",
   "metadata": {},
   "source": [
    "You can define Comparisons with a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5505be4-d750-4963-9542-170685c140f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from splink.comparison import Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28928a7-4ec4-4055-b98b-7a3877fd37dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "capacity_comparison = {\n",
    "    \"output_column_name\": \"capacity_mw\",\n",
    "    \"comparison_levels\": [\n",
    "        cll.null_level(\"capacity_mw\"),\n",
    "        cll.percentage_difference_level(\"capacity_mw\", 0.0 + 1e-4),  # could add an exact match level too\n",
    "        cll.percentage_difference_level(\"capacity_mw\", 0.1 + 1e-4), # need the 1e-4?\n",
    "        cll.percentage_difference_level(\"capacity_mw\", 0.2 + 1e-4),\n",
    "        cll.else_level(),\n",
    "    ],\n",
    "    \"comparison_description\": \"0% different vs. 10% different vs. 20% different vs. anything else\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8a1d7a-f589-4218-affb-fbc5975e03ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Comparison(capacity_comparison).human_readable_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3d7d99-8eea-4d54-a28a-a56f4eea5531",
   "metadata": {},
   "source": [
    "Do comparison levels with less than or equal formats need to be exclusive of each other? (seems like no based on the `percentage_difference_level` built in level above.\n",
    "\n",
    "https://moj-analytical-services.github.io/splink/demos/example_transactions.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69130dd7-c04a-4705-bc42-c6656d715ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_within_n_years_str(col_name, n):\n",
    "    return f\"abs({col_name}_r - {col_name}_l) <= {n}\"\n",
    " \n",
    "installation_year_comparison = {\n",
    "    \"output_column_name\": \"installation_year\",\n",
    "    \"comparison_levels\": [\n",
    "        cll.null_level(\"installation_year\"),\n",
    "        cll.exact_match_level(\"installation_year\"),\n",
    "        {\"sql_condition\": get_within_n_years_str(\"installation_year\", 1), \"label_for_charts\": \"<= 1 year diff\"},\n",
    "        {\"sql_condition\": get_within_n_years_str(\"installation_year\", 2), \"label_for_charts\": \"<= 2 years diff\"},\n",
    "        cll.else_level()\n",
    "    ],\n",
    "    \"comparison_description\": \"Number of years apart\"\n",
    "}\n",
    "\n",
    "construction_year_comparison = {\n",
    "    \"output_column_name\": \"construction_year\",\n",
    "    \"comparison_levels\": [\n",
    "        cll.null_level(\"construction_year\"),\n",
    "        cll.exact_match_level(\"construction_year\"),\n",
    "        {\"sql_condition\": get_within_n_years_str(\"construction_year\", 1), \"label_for_charts\": \"<= 1 year diff\"},\n",
    "        {\"sql_condition\": get_within_n_years_str(\"construction_year\", 2), \"label_for_charts\": \"<= 2 years diff\"},\n",
    "        cll.else_level()\n",
    "    ],\n",
    "    \"comparison_description\": \"Number of years apart\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d98a30-ea1a-4fcb-828a-b21f07da19bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Comparison(installation_year_comparison).human_readable_description)\n",
    "print(Comparison(construction_year_comparison).human_readable_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6229dc19-dc7c-4801-a474-085e578173be",
   "metadata": {},
   "source": [
    "Add `term_frequency_adjustments` to other columns?\n",
    "\n",
    "Leaving off `technology_description` for now. The match is too bad so some column adjustments need to be made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cdde7e-736f-4b57-ab95-83117db7a50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_dict.update({\n",
    "    \"comparisons\": [\n",
    "        cl.levenshtein_at_thresholds(\"plant_name\", [2, 5]),\n",
    "        cl.levenshtein_at_thresholds(\"utility_name\", [2, 5]),\n",
    "        construction_year_comparison,\n",
    "        installation_year_comparison,\n",
    "        capacity_comparison,\n",
    "        cl.exact_match(\"fuel_type_code_pudl\", term_frequency_adjustments=True),\n",
    "    ],\n",
    "    \"retain_matching_columns\": True,\n",
    "    \"retain_intermediate_calculation_columns\": False,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83044612-921a-420b-86d3-796c94412df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker = DuckDBLinker([ferc_df, eia_df], settings_dict=settings_dict, input_table_aliases=[\"_ferc\", \"_eia\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9403fde3-d3e0-4497-8d48-42aed388636f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Estimate Model Parameters\n",
    "- We can estimate the m value with both labeled training data and with unsupervised EM method.\n",
    "\n",
    "The u and m probabilities are parameters nested within each comparison level that can be viwed.\n",
    "\n",
    "These m and u estimation functions update the values and return nothing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a16375-52fe-4adb-80f1-087e548fa137",
   "metadata": {},
   "source": [
    "The u parameters represent the proportion of record comparisons that fall into each comparison level amongst truly non-matching records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9585b738-74ff-45a9-8197-bcc7ab30a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# run time goes down to 1 min with target_rows = 1e7\n",
    "linker.estimate_u_using_random_sampling(target_rows=1e8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad70ef7-65cf-42d7-99dd-7d9a97957e03",
   "metadata": {},
   "source": [
    "Try with labeled data? Could try with the 2020 training data but there isn't very much of it so ideally this m value estimation is unsupervised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29645acb-5a23-4a44-86ef-2886aa34d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# feeding it a no impact blocking rule, or does this have any impact?\n",
    "linker.estimate_parameters_using_expectation_maximisation(\"l.report_year == r.report_year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04d0f57-5f0c-4b23-a0ca-20f55e5a9056",
   "metadata": {},
   "source": [
    "The `u` values are the proportion of records falling into each ComparisonLevel amongst truly non-matching records.\n",
    "\n",
    "The `m` values are the proportion of records falling into each ComparisonLevel amongst truly matching records.\n",
    "\n",
    "TODO:\n",
    "This isn't looking great: A much larger percentage of matches should have a match on `plant_name` or `utility_name`.\n",
    "- Make the edit distance threshold larger for `plant_name` and `utility_name`. \n",
    "- Raise thresholds for `capacity_mw`?\n",
    "- Do the levels need to be exclusive of each other? i.e. if `capacity_mw` diff < 10% it shouldn't fall into the <20% category as well?\n",
    "- Add in columns / dictionaries to map to plant type.\n",
    "- Try training with labels\n",
    "- Mess with `term_frequency_adjustments`. Watch tutorial to see what they say about skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52b38b6-8cfd-4672-8898-8ab9e7ea55f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker.match_weights_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fb81e9-848d-4e5a-8488-260794d55ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker.m_u_parameters_chart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb3c0c-16ba-4c96-b4bc-10ec4beb995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_settings_name = \"plant_gen_2020_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97180f9-9f0c-4b5c-a3fe-11cd0b8625a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = linker.save_settings_to_json(f\"./splink_model_settings/{model_settings_name}.json\", overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a3a2fb-c890-4a3f-8ed9-344d70c0bbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# linker = DuckDBLinker([ferc_df, eia_df])\n",
    "# linker.load_settings_from_json(f\"./splink_model_settings/{model_settings_name}.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9312500-00d1-4be1-8c58-7025724e712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_preds = linker.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2124ab7f-901a-4138-9f95-7e28c05e432d",
   "metadata": {},
   "source": [
    "Had trouble getting this as a pandas dataframe - df_preds.as_pandas_dataframe() without a limit set hung the kernel.\n",
    "\n",
    "Look at source code to see what this function is actually doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14caa74d-21f4-4fe2-b938-d04ba99ada65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds.as_pandas_dataframe(limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ca484-21ec-42d1-9ad5-04f970b8bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to set retain_intermediate_calculations and retain_matching_columns to True in settings dictionary for prediction charts to work\n",
    "records_to_view  = df_preds.as_record_dict(limit=5)\n",
    "linker.waterfall_chart(records_to_view, filter_nulls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff5f1a7-d35f-42d7-a93e-38b2a27a56d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "linker.comparison_viewer_dashboard(df_preds, \"test.html\", overwrite=True)\n",
    "\n",
    "# You can view the scv.html file in your browser, or inline in a notbook as follows\n",
    "from IPython.display import IFrame\n",
    "IFrame(\n",
    "    src=\"./test.html\", width=\"100%\", height=1200\n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f7098b-efa3-4289-b69e-4af3882aebf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccai-em",
   "language": "python",
   "name": "ccai-em"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
